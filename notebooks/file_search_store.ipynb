{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b1ec65",
   "metadata": {},
   "source": [
    "# File Search Store Management for Rickbot\n",
    "\n",
    "A notebook to experiment with the FileSearchStore and how it can be used to manage file search in the Rickbot Agent.\n",
    "\n",
    "The best way to run this notebook is from Google Colab.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/derailed-dash/rickbot-adk/blob/main/notebooks/file_search_store.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639f75a",
   "metadata": {},
   "source": [
    "## Pre-Reqs and Notes\n",
    "\n",
    "- The `file_search_stores` is a feature exclusive to the Gemini Developer API. \n",
    "  - It does not work with the Vertex AI API or the Gen AI SDK in Vertex AI mode.\n",
    "  - Therefore: don't set env vars for `GOOGLE_CLOUD_LOCATION` or `GOOGLE_GENAI_USE_VERTEXAI` and do not initialise Vertex AI.\n",
    "- Make sure you have an up-to-date version of the `google-genai` package installed. \n",
    "  - Versions older than 1.49.0 do not support the File Search Tool.\n",
    "  - You can upgrade the package using `pip install --upgrade google-genai`.\n",
    "  - You can add to your `pyproject.toml` file; since we don't explicitly need it outside of this notebook, we can add it to the `[jupyter]` section.\n",
    "- Add your Gemini API Key to Colab as a secret. Then you can retrieve it using `userdata.get(\"GEMINI_API_KEY\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68e9c1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97210f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai.types import Document, FileSearchStore\n",
    "from pydantic import BaseModel\n",
    "# from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576bcec",
   "metadata": {},
   "source": [
    "\n",
    "### Local Only\n",
    "\n",
    "If running locally, setup the Google Cloud environment:\n",
    "\n",
    "```bash\n",
    "source scripts/setup-env.sh\n",
    "```\n",
    "\n",
    "Then to install the package dependencies into the virtual environment, use the `uv` tool:\n",
    "\n",
    "1. From your agent's root directory, run `make install` to set up the virtual environment (`.venv`).\n",
    "2. In this Jupyter notebook, select the kernel from the `.venv` folder to ensure all dependencies are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env\n",
      "Successfully loaded Google API key.\n"
     ]
    }
   ],
   "source": [
    "if load_dotenv(\".env.local\"):\n",
    "    print(\"Loaded env\")\n",
    "else:\n",
    "    print(\"Warning: .env file not found\")\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set.\")\n",
    "else:\n",
    "    print(\"Successfully loaded Gemini API key.\")\n",
    "\n",
    "APP_NAME = \"rickbot_notebook_client\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a6f7f",
   "metadata": {},
   "source": [
    "### Or In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U \"google-genai>=1.49.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a074a3",
   "metadata": {},
   "source": [
    "### Client Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad5175e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "DAZBO_STORE_NAME = \"rickbot-dazbo-ref\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42055dd4",
   "metadata": {},
   "source": [
    "## Store Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9c175",
   "metadata": {},
   "source": [
    "### View All Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1ec353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='fileSearchStores/rickbotdazboref-akasbs0scqrs' display_name='rickbot-dazbo-ref' create_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) active_documents_count=None pending_documents_count=None failed_documents_count=None size_bytes=None\n"
     ]
    }
   ],
   "source": [
    "for a_store in client.file_search_stores.list():\n",
    "    print(a_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0dfbd",
   "metadata": {},
   "source": [
    "### Retrieve the Store\n",
    "\n",
    "Here's a utility function to retrieve the store(s) that match a given display name. Note that display name is not unique, so this function returns the first matching store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6b80190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store(store_name: str) -> FileSearchStore | None:\n",
    "    \"\"\" Retrieve a store by display name \"\"\"\n",
    "    for a_store in client.file_search_stores.list():\n",
    "        if a_store.display_name == store_name:\n",
    "            return a_store\n",
    "\n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3346a",
   "metadata": {},
   "source": [
    "### Create the Store (One Time)\n",
    "\n",
    "Once you've created the store, save the store ID for use in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_search_store = client.file_search_stores.create(config={'display_name': DAZBO_STORE_NAME})\n",
    "print(file_search_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe601a",
   "metadata": {},
   "source": [
    "### View the Store\n",
    "\n",
    "We can interrogate a store and see what files have been uploaded to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc694cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='fileSearchStores/rickbotdazboref-akasbs0scqrs' display_name='rickbot-dazbo-ref' create_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) active_documents_count=1 pending_documents_count=None failed_documents_count=None size_bytes=7011965\n",
      "Docs in rickbot-dazbo-ref: 1\n",
      "-----------\n",
      "Document 0:\n",
      "-----------\n",
      "  Display name:1b - Reducing Software License Costs with Open Source (Google Cloud Adoption Series) _ by Dazbo (Darren Lester) _ Medium.pdf\n",
      "  ID: fileSearchStores/rickbotdazboref-akasbs0scqrs/documents/1b-reducing-software-licens-pygk53ktwxa9\n",
      "  Metadata: [CustomMetadata(\n",
      "  key='file_name',\n",
      "  string_value='1b - Reducing Software License Costs with Open Source (Google Cloud Adoption Series) _ by Dazbo (Darren Lester) _ Medium.pdf'\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "file_search_store = get_store(DAZBO_STORE_NAME)\n",
    "if not file_search_store:\n",
    "    print(f\"Store {DAZBO_STORE_NAME} not found.\")\n",
    "else:\n",
    "    print(file_search_store)\n",
    "    print(f\"Docs in {DAZBO_STORE_NAME}: {file_search_store.active_documents_count}\")\n",
    "\n",
    "    # List all documents in the store\n",
    "    # The 'parent' argument is the resource name of the store\n",
    "    docs = client.file_search_stores.documents.list(parent=file_search_store.name)\n",
    "    if not docs:\n",
    "        print(\"No documents found in the store.\")\n",
    "    else:\n",
    "        for i, doc in enumerate(docs):\n",
    "            section_heading = f\"Document {i}:\"\n",
    "            print(\"-\" * len(section_heading))\n",
    "            print(section_heading)\n",
    "            print(\"-\" * len(section_heading))\n",
    "            print(f\"  Display name:{doc.display_name}\")\n",
    "            print(f\"  ID: {doc.name}\")\n",
    "            print(f\"  Metadata: {doc.custom_metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82077a",
   "metadata": {},
   "source": [
    "### Delete Store(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d6987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting name='fileSearchStores/rickbotdazboref-akasbs0scqrs' display_name='rickbot-dazbo-ref' create_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 12, 31, 16, 41, 49, 4605, tzinfo=TzInfo(0)) active_documents_count=None pending_documents_count=None failed_documents_count=None size_bytes=None\n"
     ]
    }
   ],
   "source": [
    "# First, point to the right store. For example:\n",
    "file_search_store = get_store(DAZBO_STORE_NAME)\n",
    "\n",
    "# Delete the store\n",
    "if file_search_store:\n",
    "    print(f\"Deleting {file_search_store}\")\n",
    "    # Uncomment to delete\n",
    "    # client.file_search_stores.delete(name=file_search_store.name, config={'force': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11668f60",
   "metadata": {},
   "source": [
    "## Upload and Process Files\n",
    "\n",
    "Now we need to place the files in a suitable local folder to upload to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_PATH = \"/content/upload-files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    abstract: str\n",
    "\n",
    "def delete_doc(doc: Document, file_search_store):\n",
    "    \"\"\" Delete document(s) from the file search store \"\"\"\n",
    "    print(f\"♻️  Deleting duplicate: '{doc.display_name}' (ID: {doc.name})\")\n",
    "    client.file_search_stores.documents.delete(\n",
    "        name=doc.name, \n",
    "        config={'force': True}\n",
    "    )\n",
    "    time.sleep(2) # small throttle and allow propagation\n",
    "\n",
    "def generate_metadata(file_name: str, temp_file) -> DocumentMetadata:\n",
    "    \"\"\" Generate metadata for a document \"\"\"\n",
    "\n",
    "    print(f\"Extracting metadata from {file_name}...\")    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[\n",
    "            \"\"\"Please extract title, author, and short abstract from this document. \n",
    "            Each value should be under 200 characters.\n",
    "\n",
    "            Abstracts should be succinct and NOT include preamble text like `This document describes...`\n",
    "\n",
    "            Example bad abstract: \n",
    "            Now I want to cover a key consideration that can potentially \n",
    "            save you more in future IT spend than any other decision you can make: \n",
    "            embracing open source as a core element of your cloud strategy.\n",
    "\n",
    "            Example good abstract:\n",
    "            How you can significantly reduce IT spend by embracing open source\n",
    "            as a core component of your cloud strategy.\n",
    "\n",
    "            Example bad abstract:\n",
    "            This article discusses how you can design your cloud landing zone.\n",
    "\n",
    "            Example good abstract:\n",
    "            How to design your cloud landing zone according to best practices.\n",
    "            \"\"\",\n",
    "            temp_file\n",
    "        ],\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": DocumentMetadata,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    metadata: DocumentMetadata = response.parsed\n",
    "    print(f\"Title: {metadata.title}\")\n",
    "    print(f\"Author: {metadata.author}\")\n",
    "    print(f\"Abstract: {metadata.abstract}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def upload_doc(file_path, file_search_store):\n",
    "    \"\"\" Upload a document to the file search store \"\"\"\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    print(f\"Uploading {file_name} for metadata extraction...\")\n",
    "    temp_file = client.files.upload(file=file_path)\n",
    "\n",
    "    # Verify file is active (ready for inference)\n",
    "    while temp_file.state.name == \"PROCESSING\":\n",
    "        print(\"Still uploading...\", end='\\r')\n",
    "        time.sleep(2)\n",
    "        temp_file = client.files.get(name=temp_file.name)\n",
    "\n",
    "    if temp_file.state.name != \"ACTIVE\":\n",
    "        raise RuntimeError(f\"File upload failed with state: {temp_file.state.name}\")\n",
    "\n",
    "    # Now let's check if this is a replacement of an existing file\n",
    "    # If so, we should delete the existing entry first\n",
    "    # Iterate through all docs in the store\n",
    "    for doc in client.file_search_stores.documents.list(parent=file_search_store.name):\n",
    "        should_delete = False\n",
    "\n",
    "        # Match by Display Name\n",
    "        if doc.display_name == file_name:\n",
    "            should_delete = True\n",
    "\n",
    "        # Match by Custom Metadata (Robust Match)\n",
    "        # This catches docs where display_name was set to the Title\n",
    "        elif doc.custom_metadata:\n",
    "            for meta in doc.custom_metadata:\n",
    "                if meta.key == \"file_name\" and meta.string_value == file_name:\n",
    "                    should_delete = True\n",
    "                    break\n",
    "\n",
    "        if should_delete:\n",
    "            delete_doc(doc, file_search_store)\n",
    "\n",
    "    metadata = generate_metadata(file_name, temp_file)\n",
    "\n",
    "    # Import the file into the file search store with custom metadata\n",
    "    operation = client.file_search_stores.upload_to_file_search_store(\n",
    "        file_search_store_name=file_search_store.name,\n",
    "        file = file_path,\n",
    "        config={'display_name' : metadata.title, # or we could determine the title\n",
    "                # 'chunking_config' : chunking_config[\"chunking_config\"],\n",
    "                'custom_metadata':[\n",
    "                    {\"key\": \"title\", \"string_value\": metadata.title},\n",
    "                    {\"key\": \"file_name\", \"string_value\": file_name},\n",
    "                    {\"key\": \"author\", \"string_value\": metadata.author},\n",
    "                    {\"key\": \"abstract\", \"string_value\": metadata.abstract},\n",
    "                ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Wait until import is complete\n",
    "    while not operation.done:\n",
    "        time.sleep(5)\n",
    "        print(\"Still importing...\")\n",
    "        operation = client.operations.get(operation)\n",
    "\n",
    "    print(f\"{file_name} successfully uploaded and indexed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb63221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files to fileSearchStores/rickbotdazboref-akasbs0scqrs...\n"
     ]
    }
   ],
   "source": [
    "file_search_store = get_store(DAZBO_STORE_NAME)\n",
    "if file_search_store is None:\n",
    "    print(f\"Store {DAZBO_STORE_NAME} not found.\")\n",
    "else:\n",
    "    print(f\"Uploading files to {file_search_store.name}...\")\n",
    "    files_to_upload = glob.glob(f'{UPLOAD_PATH}/*')\n",
    "    if files_to_upload:\n",
    "        for file_path in files_to_upload:\n",
    "            print(f\"Uploading {file_path}\")\n",
    "            upload_doc(file_path, file_search_store)\n",
    "    else:\n",
    "        print(f\"No files found in {UPLOAD_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
